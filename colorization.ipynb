{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Welcome to our EECS 442 project: Colorization of Iconic Sports Photos"
      ],
      "metadata": {
        "id": "JNOl4N3mXAbh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znW9wWXgrZDy",
        "outputId": "2d370d13-7d56-40e4-aa7a-08c6a3b7f963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huhMrHOdrl__"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
        "# Example: If you create a EECS442 folder and put all the files under HW5 folder, then 'EECS442/HW5'\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'EECS442_Project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g8mdaPytl-G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQfqllpsu5aU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb69ee96-5f11-43ba-d1fa-c0a95273fdea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/EECS442_Project\n"
          ]
        }
      ],
      "source": [
        "print(GOOGLE_DRIVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/EECS442_Project"
      ],
      "metadata": {
        "id": "QWeNjXw_NNfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864837da-8539-4367-f20d-3a8c7b8fb9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ckixt1SXyEJ89NxG9GoD7MfjvT8tKVu_/EECS442_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the packages needed"
      ],
      "metadata": {
        "id": "4XWLp2zWXx-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import itertools\n",
        "from matplotlib import image\n",
        "import glob as glob\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchsummary import summary\n",
        "from skimage import color\n",
        "from skimage.color import rgb2lab, lab2rgb"
      ],
      "metadata": {
        "id": "ykoSXHWtWncY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader:"
      ],
      "metadata": {
        "id": "gTClb6_AfV7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecolorData(Dataset):\n",
        "  def __init__(self, root_dir, size=128, split='train', transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        root_dir: the directory of the dataset\n",
        "        split: \"train\", \"valid\", or \"test\"\n",
        "        transform: pytorch transformations.\n",
        "    \"\"\"\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "    self.files = glob.glob(os.path.join(root_dir, split + str(size), '*.jpg'))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.files[idx])\n",
        "    img = color.rgb2lab(img).astype(\"float32\")\n",
        "    img = np.asarray(img)\n",
        "    if self.transform:\n",
        "        img = self.transform(img)\n",
        "    return {'L': img[0:1, :, :], 'ab': img[1:3, :, :]}"
      ],
      "metadata": {
        "id": "YQxvVA6QeIVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "%cd Downloads/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Utyejb_W05U",
        "outputId": "9757b1e1-a903-4ce2-a9d7-4289dbc7bdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;31mcode_1.87.2-1709912201_amd64.deb\u001b[0m\r\n",
            "\u001b[01;34mdataset128\u001b[0m/\r\n",
            "\u001b[01;31mdataset128.zip\u001b[0m\r\n",
            "\u001b[01;34mSpinnaker\u001b[0m/\r\n",
            "\u001b[01;31mspinnaker-4.0.0.116-amd64-pkg-22.04.tar.gz\u001b[0m\r\n",
            "\u001b[01;31mspinnaker_python-4.0.0.116-cp310-cp310-linux_x86_64.tar.gz\u001b[0m\r\n",
            "[Errno 2] No such file or directory: 'Downloads/'\n",
            "/home/mcity/Downloads\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/mcity/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformation to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    #transforms.Resize((256, 256)),  # Resize images to a fixed size\n",
        "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the images\n",
        "])\n",
        "\n",
        "# Define the directory containing your image folders\n",
        "data_dir = 'dataset128'\n",
        "\n",
        "# Load the dataset using ImageFolder\n",
        "train_dataset = RecolorData(data_dir, split=\"train\", transform=transform)\n",
        "valid_dataset = RecolorData(data_dir, split=\"valid\", transform=transform)\n",
        "test_dataset = RecolorData(data_dir, split=\"test\", transform=transform)\n",
        "\n",
        "print(len(train_dataset))\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create a DataLoader to iterate over the dataset\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print('Number of training images {}, number of validation images {}, number of testing images {}'.format(len(train_dataset), len(valid_dataset), len(test_dataset)))\n",
        "\n",
        "data = next(iter(train_dl))\n",
        "Ls, abs_ = data['L'], data['ab']\n",
        "print(Ls.shape, abs_.shape)\n",
        "print(len(train_dl), len(val_dl))"
      ],
      "metadata": {
        "id": "Jrfg5xHTeKvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577e54c0-eb11-464d-8690-d901bbe4ed51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13492\n",
            "Number of training images 13492, number of validation images 500, number of testing images 500\n",
            "torch.Size([16, 1, 128, 128]) torch.Size([16, 2, 128, 128])\n",
            "844 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net"
      ],
      "metadata": {
        "id": "kRIrKHItV88f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import e\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
        "        super().__init__()\n",
        "        self.layer1_d = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 4, stride=2, padding=1),\n",
        "        )\n",
        "        self.layer2_d = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.layer3_d = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.layer4_d = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "        self.layer5_d = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512)\n",
        "        )\n",
        "        self.layer6_d = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(512, 1024, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(1024)\n",
        "        )\n",
        "        self.layer7_d = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(1024, 1024, 4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        self.layer7_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(1024, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(1024)\n",
        "        )\n",
        "        self.layer6_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(2048, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512)\n",
        "        )\n",
        "        self.layer5_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(1024, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "        self.layer4_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.layer3_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.layer2_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.layer1_u = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 2, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.up_layers = [self.layer1_u, self.layer2_u, self.layer3_u, self.layer4_u, self.layer5_u, self.layer6_u, self.layer7_u]\n",
        "        self.down_layers = [self.layer1_d, self.layer2_d, self.layer3_d, self.layer4_d, self.layer5_d, self.layer6_d, self.layer7_d]\n",
        "\n",
        "        # self.init_weights()\n",
        "\n",
        "    def init_weights(self, mean, std):\n",
        "      for m in self._modules:\n",
        "        if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "          m.weight.data.normal_(mean, std)\n",
        "          m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        #down (encode)\n",
        "        e1 = self.layer1_d(input)\n",
        "        e2 = self.layer2_d(e1)\n",
        "        e3 = self.layer3_d(e2)\n",
        "        e4 = self.layer4_d(e3)\n",
        "        e5 = self.layer5_d(e4)\n",
        "        e6 = self.layer6_d(e5)\n",
        "        e7 = self.layer7_d(e6)\n",
        "\n",
        "        #up (decode)\n",
        "        d7 = self.layer7_u(e7)\n",
        "        d7 = torch.cat([d7, e6], 1)\n",
        "        d6 = self.layer6_u(d7)\n",
        "        d6 = torch.cat([d6, e5], 1)\n",
        "        d5 = self.layer5_u(d6)\n",
        "        d5 = torch.cat([d5, e4], 1)\n",
        "        d4 = self.layer4_u(d5)\n",
        "        d4 = torch.cat([d4, e3], 1)\n",
        "        d3 = self.layer3_u(d4)\n",
        "        d3 = torch.cat([d3, e2], 1)\n",
        "        d2 = self.layer2_u(d3)\n",
        "        d2 = torch.cat([d2, e1], 1)\n",
        "        d1= self.layer1_u(d2)\n",
        "\n",
        "        return d1"
      ],
      "metadata": {
        "id": "GdeP8iPUFioS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "\n",
        "Patch Discriminator Bx3x128x128 to Bx1x15x15"
      ],
      "metadata": {
        "id": "-2p5MqiyVyOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "  # initializers\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(256)\n",
        "    self.conv4 = nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1)\n",
        "    #self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1)\n",
        "    #self.bn4 = nn.BatchNorm2d(512)\n",
        "    #self.conv5 = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "  # weight_init - Doesn't work as normal_init is not defined\n",
        "  def weight_init(self, mean, std):\n",
        "    for m in self._modules:\n",
        "      normal_init(self._modules[m], mean, std)\n",
        "\n",
        "\n",
        "  def init_weights(self, mean, std):\n",
        "      for m in self._modules:\n",
        "        if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "          m.weight.data.normal_(mean, std)\n",
        "          m.bias.data.zero_()\n",
        "\n",
        "\n",
        "  # forward method\n",
        "  def forward(self, input):\n",
        "\n",
        "    x1 = F.leaky_relu(self.conv1(input))\n",
        "    x2 = F.leaky_relu(self.bn2(self.conv2(x1)), negative_slope=0.1)\n",
        "    x3 = F.leaky_relu(self.bn3(self.conv3(x2)), negative_slope=0.1)\n",
        "    x4 = self.conv4(x3)\n",
        "    #x4 = F.leaky_relu(self.bn4(self.conv4(x3)), negative_slope=0.2)\n",
        "    #x4 = F.sigmoid(self.conv4(x3))\n",
        "\n",
        "    return x4"
      ],
      "metadata": {
        "id": "CyZd0IQ2VyEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN Loss\n",
        "\n",
        "Not currently used"
      ],
      "metadata": {
        "id": "WgJ8_n3fV5sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def __call__(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "rdEWhFGAL1BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "CfY5P8lUvXkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = Unet().cuda()\n",
        "D = PatchDiscriminator().cuda()\n",
        "summary(G, (1, 128, 128))\n",
        "summary(D, (3, 128, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlVwB5bivZBI",
        "outputId": "9eb4de4c-f6b9-48a9-a476-64373deab83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 64, 64]             544\n",
            "         LeakyReLU-2           [-1, 32, 64, 64]               0\n",
            "            Conv2d-3           [-1, 64, 32, 32]          32,832\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "         LeakyReLU-5           [-1, 64, 32, 32]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]         131,200\n",
            "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
            "         LeakyReLU-8          [-1, 128, 16, 16]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         524,544\n",
            "      BatchNorm2d-10            [-1, 256, 8, 8]             512\n",
            "        LeakyReLU-11            [-1, 256, 8, 8]               0\n",
            "           Conv2d-12            [-1, 512, 4, 4]       2,097,664\n",
            "      BatchNorm2d-13            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-14            [-1, 512, 4, 4]               0\n",
            "           Conv2d-15           [-1, 1024, 2, 2]       8,389,632\n",
            "      BatchNorm2d-16           [-1, 1024, 2, 2]           2,048\n",
            "        LeakyReLU-17           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-18           [-1, 1024, 1, 1]      16,778,240\n",
            "             ReLU-19           [-1, 1024, 1, 1]               0\n",
            "  ConvTranspose2d-20           [-1, 1024, 2, 2]      16,777,216\n",
            "      BatchNorm2d-21           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-22           [-1, 2048, 2, 2]               0\n",
            "  ConvTranspose2d-23            [-1, 512, 4, 4]      16,777,216\n",
            "      BatchNorm2d-24            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-25           [-1, 1024, 4, 4]               0\n",
            "  ConvTranspose2d-26            [-1, 256, 8, 8]       4,194,304\n",
            "      BatchNorm2d-27            [-1, 256, 8, 8]             512\n",
            "             ReLU-28            [-1, 512, 8, 8]               0\n",
            "  ConvTranspose2d-29          [-1, 128, 16, 16]       1,048,576\n",
            "      BatchNorm2d-30          [-1, 128, 16, 16]             256\n",
            "             ReLU-31          [-1, 256, 16, 16]               0\n",
            "  ConvTranspose2d-32           [-1, 64, 32, 32]         262,144\n",
            "      BatchNorm2d-33           [-1, 64, 32, 32]             128\n",
            "             ReLU-34          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-35           [-1, 32, 64, 64]          65,536\n",
            "      BatchNorm2d-36           [-1, 32, 64, 64]              64\n",
            "             ReLU-37           [-1, 64, 64, 64]               0\n",
            "  ConvTranspose2d-38          [-1, 2, 128, 128]           2,050\n",
            "             Tanh-39          [-1, 2, 128, 128]               0\n",
            "================================================================\n",
            "Total params: 67,089,698\n",
            "Trainable params: 67,089,698\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 13.30\n",
            "Params size (MB): 255.93\n",
            "Estimated Total Size (MB): 269.29\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           3,136\n",
            "            Conv2d-2          [-1, 128, 32, 32]         131,200\n",
            "       BatchNorm2d-3          [-1, 128, 32, 32]             256\n",
            "            Conv2d-4          [-1, 256, 16, 16]         524,544\n",
            "       BatchNorm2d-5          [-1, 256, 16, 16]             512\n",
            "            Conv2d-6            [-1, 1, 15, 15]           4,097\n",
            "================================================================\n",
            "Total params: 663,745\n",
            "Trainable params: 663,745\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 5.00\n",
            "Params size (MB): 2.53\n",
            "Estimated Total Size (MB): 7.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers"
      ],
      "metadata": {
        "id": "Z5Dh8u9RgbDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lab_to_rgb(L, ab):\n",
        "    \"\"\"\n",
        "    Takes a batch of images\n",
        "    \"\"\"\n",
        "\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def visualize(G, data, save=True):\n",
        "    L = data['L']\n",
        "    real_color = data['ab']\n",
        "    fake_color = G(L)\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "    if save:\n",
        "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
        "\n",
        "def log_results(loss_meter_dict):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
      ],
      "metadata": {
        "id": "n_8AXsUO0rP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Sample Output used for visualization\n",
        "test = val_dl.__iter__().__next__()\n",
        "img_size = 256\n",
        "fixed_y_ = test['ab'].cuda()\n",
        "fixed_x_ = test['L'].cuda()\n",
        "print(len(train_dl))\n",
        "print(len(val_dl))\n",
        "print(fixed_y_.shape)\n",
        "\n",
        "# plot sample image\n",
        "fig, axes = plt.subplots(2, 2)\n",
        "axes = np.reshape(axes, (4, ))\n",
        "for i in range(4):\n",
        "  example = train_dl.__iter__().__next__()[i].numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.5, 0.5, 0.5])\n",
        "  std = np.array([0.5, 0.5, 0.5])\n",
        "  example = std * example + mean\n",
        "  axes[i].imshow(example)\n",
        "  axes[i].axis('off')\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "Ws8-ilBB0L5K",
        "outputId": "b6b4e2e8-2061-4552-bb3f-046653b007df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#Sample Output used for visualization\\ntest = val_dl.__iter__().__next__()\\nimg_size = 256\\nfixed_y_ = test['ab'].cuda()\\nfixed_x_ = test['L'].cuda()\\nprint(len(train_dl))\\nprint(len(val_dl))\\nprint(fixed_y_.shape)\\n\\n# plot sample image\\nfig, axes = plt.subplots(2, 2)\\naxes = np.reshape(axes, (4, ))\\nfor i in range(4):\\n  example = train_dl.__iter__().__next__()[i].numpy().transpose((1, 2, 0))\\n  mean = np.array([0.5, 0.5, 0.5])\\n  std = np.array([0.5, 0.5, 0.5])\\n  example = std * example + mean\\n  axes[i].imshow(example)\\n  axes[i].axis('off')\\nplt.show()\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(img):\n",
        "  return (img.cpu().data.numpy().transpose(1, 2, 0) + 1) / 2\n",
        "\n",
        "def show_result(G, x_, y_, num_epoch):\n",
        "  predict_images = G(x_)\n",
        "\n",
        "  fig, ax = plt.subplots(x_.size()[0], 3, figsize=(6,10))\n",
        "\n",
        "  for i in range(x_.size()[0]):\n",
        "    ax[i, 0].get_xaxis().set_visible(False)\n",
        "    ax[i, 0].get_yaxis().set_visible(False)\n",
        "    ax[i, 1].get_xaxis().set_visible(False)\n",
        "    ax[i, 1].get_yaxis().set_visible(False)\n",
        "    ax[i, 2].get_xaxis().set_visible(False)\n",
        "    ax[i, 2].get_yaxis().set_visible(False)\n",
        "    ax[i, 0].cla()\n",
        "    ax[i, 0].imshow(process_image(x_[i]))\n",
        "    ax[i, 1].cla()\n",
        "    ax[i, 1].imshow(process_image(predict_images[i]))\n",
        "    ax[i, 2].cla()\n",
        "    ax[i, 2].imshow(process_image(y_[i]))\n",
        "\n",
        "  plt.tight_layout()\n",
        "  label_epoch = 'Epoch {0}'.format(num_epoch)\n",
        "  fig.text(0.5, 0, label_epoch, ha='center')\n",
        "  label_input = 'Input'\n",
        "  fig.text(0.18, 1, label_input, ha='center')\n",
        "  label_output = 'Output'\n",
        "  fig.text(0.5, 1, label_output, ha='center')\n",
        "  label_truth = 'Ground truth'\n",
        "  fig.text(0.81, 1, label_truth, ha='center')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "# Helper function for counting number of trainable parameters.\n",
        "def count_params(model):\n",
        "  '''\n",
        "  Counts the number of trainable parameters in PyTorch.\n",
        "  Args:\n",
        "      model: PyTorch model.\n",
        "  Returns:\n",
        "      num_params: int, number of trainable parameters.\n",
        "  '''\n",
        "  num_params = sum([item.numel() for item in model.parameters() if item.requires_grad])\n",
        "  return num_paramsG_100"
      ],
      "metadata": {
        "id": "3z3MsTLGgab9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint: you could use following loss to complete following function\n",
        "BCE_loss = nn.BCEWithLogitsLoss().cuda()\n",
        "L1_loss = nn.L1Loss().cuda()\n",
        "\n",
        "def train(G, D, num_epochs = 20):\n",
        "  hist_D_losses = []\n",
        "  hist_G_losses = []\n",
        "  hist_G_L1_losses = []\n",
        "\n",
        "  lr=0.0002\n",
        "  beta=0.5\n",
        "  beta2=0.999\n",
        "  G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(beta, beta2))\n",
        "  D_optimizer = optim.Adam(D.parameters(), lr=0.5*lr, betas=(beta, beta2))\n",
        "\n",
        "\n",
        "  print('training start!')\n",
        "  start_time = time.time()\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Start training epoch %d' % (epoch + 1))\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "    epoch_start_time = time.time()\n",
        "    num_iter = 0\n",
        "    for batch in train_dl:\n",
        "      x_ = batch['L'].cuda()\n",
        "      y_ = batch['ab'].cuda()\n",
        "\n",
        "      #optimize D\n",
        "      D_optimizer.zero_grad()\n",
        "\n",
        "      #real data\n",
        "      D_real_preds = D(torch.cat([x_, y_], dim=1))\n",
        "      D_real_loss = BCE_loss(D_real_preds, torch.ones_like(D_real_preds).cuda())\n",
        "\n",
        "      #fake data\n",
        "      fake_data = G(x_)\n",
        "      D_fake_preds = D(torch.cat([x_,fake_data.detach()],dim=1))\n",
        "      D_fake_loss = BCE_loss(D_fake_preds, torch.zeros_like(D_fake_preds).cuda())\n",
        "\n",
        "      #update D\n",
        "      loss_D = (D_real_loss + D_fake_loss) / 2\n",
        "      loss_D.backward()\n",
        "      D_optimizer.step()\n",
        "\n",
        "\n",
        "      #optimize G\n",
        "      G_optimizer.zero_grad()\n",
        "\n",
        "      #Loss\n",
        "      D_fake_preds = D(torch.cat([x_,fake_data.detach()],dim=1))\n",
        "      G_BCE_loss = BCE_loss(D_fake_preds, torch.ones_like(D_fake_preds).cuda())\n",
        "      G_L1_loss = L1_loss(fake_data,y_)\n",
        "      L1_lambda = 100\n",
        "      loss_G = G_BCE_loss + L1_lambda*G_L1_loss\n",
        "\n",
        "      loss_G.backward()\n",
        "      G_optimizer.step()\n",
        "\n",
        "      hist_D_losses.append(loss_D.item())\n",
        "      hist_G_losses.append(G_BCE_loss.item())\n",
        "      hist_G_L1_losses.append(G_L1_loss.item())\n",
        "      D_losses.append(loss_D.item())\n",
        "      G_losses.append(loss_G.item())\n",
        "      num_iter += 1\n",
        "\n",
        "\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    per_epoch_ptime = epoch_end_time - epoch_start_time\n",
        "\n",
        "    print('[%d/%d] - using time: %.2f seconds' % ((epoch + 1), num_epochs, per_epoch_ptime))\n",
        "    print('loss of discriminator D: %.3f' % (torch.mean(torch.FloatTensor(D_losses))))\n",
        "    print('loss of generator G: %.3f' % (torch.mean(torch.FloatTensor(G_losses))))\n",
        "    if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "      with torch.no_grad():\n",
        "        visualize(G, batch, save=False)\n",
        "\n",
        "  end_time = time.time()\n",
        "  total_ptime = end_time - start_time\n",
        "\n",
        "  return hist_D_losses, hist_G_losses, hist_G_L1_losses"
      ],
      "metadata": {
        "id": "GhId8Eh2MLv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_100 = Unet()\n",
        "D_100 = PatchDiscriminator()\n",
        "G_100.init_weights(mean=0.0, std=0.02)\n",
        "D_100.init_weights(mean=0.0, std=0.02)\n",
        "G_100.cuda()\n",
        "D_100.cuda()\n",
        "G_100.train()\n",
        "D_100.train()"
      ],
      "metadata": {
        "id": "Y9ktaCS9SQoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3426aef7-f662-4542-87a6-88b1dc74d34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchDiscriminator(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Begin Training"
      ],
      "metadata": {
        "id": "G76ZiY9DhPd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_D_100_losses, hist_G_100_BCE_losses, hist_G_100_L1_losses = train(G_100,D_100,num_epochs=20)"
      ],
      "metadata": {
        "id": "v0hDMrwqhO8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c061782-7b10-4e87-87eb-d60741a60b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training start!\n",
            "Start training epoch 1\n"
          ]
        }
      ]
    }
  ]
}